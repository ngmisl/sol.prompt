This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
contracts/
  .git/
    hooks/
      applypatch-msg.sample
      commit-msg.sample
      docs.url
      fsmonitor-watchman.sample
      post-update.sample
      pre-applypatch.sample
      pre-commit.sample
      pre-merge-commit.sample
      pre-push.sample
      pre-rebase.sample
      prepare-commit-msg.sample
    info/
      exclude
    logs/
      refs/
        heads/
          main
        remotes/
          origin/
            main
      HEAD
    refs/
      heads/
        main
      remotes/
        origin/
          HEAD
    config
    description
    FETCH_HEAD
    HEAD
    packed-refs
  MinotaurPass.sol
  MinotaurToken.sol
  MinutaurUri.sol
.gitignore
.windurfrules
audit.prompt
go.mod
main.go
README.md
sol.prompt
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="contracts/.git/hooks/applypatch-msg.sample">
#!/bin/sh
# A sample hook to check commit messages created by `git am`
###########################################################
#
# When you receive a patch via email, the `git am` command is commonly used to apply
# that patch. During the `git am` process, the `applypatch-msg` hook is executed before
# creating the commit. Its purpose is to validate and modify the commit log message
# before the patch is applied as a commit in your Git repository.
#
# This script serves as an example to validate that the commit message introduced by
# the patch from an email would pass the `commit-msg` hook, which would be executed
# if you had created the commit yourself.
#
# This hook is the first and followed up by `pre-applypatch` and `post-applypatch`.
#
# To enable this hook remove the `.sample` suffix from this file entirely.

# Retrieve the path of the commit-msg hook script.
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"

# If the commit-msg hook script is executable, execute it and pass any command-line arguments to it.
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}

# Be sure to exit without error if `exec` isn't called.
:
</file>

<file path="contracts/.git/hooks/commit-msg.sample">
#!/bin/sh
# A sample hook to check commit messages created by `git commit`
################################################################
#
# This example script checks commit messages for duplicate `Signed-off-by`
# lines and rejects the commit if these are present.
#
# It is called by "git commit" with a single argument: the name of the file
# that contains the final commit message, which would be used in the commit.
# A a non-zero exit status after issuing an appropriate message stops the operation.
# The hook is allowed to edit the commit message file by rewriting the file
# containing it.
#
# To enable this hook remove the `.sample` suffix from this file entirely.

# Check for duplicate Signed-off-by lines in the commit message.
# The following command uses grep to find lines starting with "Signed-off-by: "
# in the commit message file specified by the first argument `$1`.
# It then sorts the lines, counts the number of occurrences of each line,
# and removes any lines that occur only once.
# If there are any remaining lines, it means there are duplicate Signed-off-by lines.
test "$(grep '^Signed-off-by: ' "$1" | sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" = "" || {
	echo "Remove duplicate Signed-off-by lines and repeat the commit." 1>&2
	exit 1
}
</file>

<file path="contracts/.git/hooks/docs.url">
https://git-scm.com/docs/githooks
</file>

<file path="contracts/.git/hooks/fsmonitor-watchman.sample">
#!/usr/bin/sh
# How to use hook-based fs-monitor integrations
###############################################

# This script is meant as a placeholder for integrating filesystem monitors with git
# using hooks in order to speed up commands like `git-status`.
#
# To setup the fs-monitor for use with watchman, run
# `git config core.fsmonitor .git/hooks/fsmonitor-watchman` and paste the content of
# the example script over at https://github.com/git/git/blob/aa9166bcc0ba654fc21f198a30647ec087f733ed/templates/hooks--fsmonitor-watchman.sample
# into `.git/hooks/fsmonitor-watchman`.
#
# Note that by now and as of this writing on MacOS and Windows and starting from git 2.35.1
# one can use the built-in fs-monitor implementation using `git config core.fsmonitor true`

exit 42
</file>

<file path="contracts/.git/hooks/post-update.sample">
#!/bin/sh
# A sample hook that runs after receiving a pack on a remote
############################################################
# This hook is called after a pack was received on the remote, i.e. after a successful `git push` operation.
# It's useful on the server side only.
#
# There many more receive hooks which are documented in the official documentation: https://git-scm.com/docs/githooks.
#
# To enable this hook remove the `.sample` suffix from this file entirely.

# Update static files to support the 'dumb' git HTTP protocol.
exec git update-server-info
</file>

<file path="contracts/.git/hooks/pre-applypatch.sample">
#!/bin/sh
# A sample hook to check commit messages created by `git am`
###########################################################

# This hook script is triggered by `git am` without any context just before creating a commit,
# which is useful to inspect the current tree or run scripts for further verification.
#
# If it exits with a non-zero exit code, the commit will not be created. Everything printed
# to the output or error channels will be visible to the user.
#
# Note that there is a sibling hook called `post-applypatch` (also without further context)
# which is run after the commit was created. It is useful to use the commit hash for further
# processing, like sending information to the involved parties.
# Finally, the `applypatch-msg` hook is called at the very beginning of the `git am` operation
# to provide access to the commit-message.
#
# To enable this hook remove the `.sample` suffix from this file entirely.

# Retrieve the path to the pre-commit hook script using the "git rev-parse" command.
precommit="$(git rev-parse --git-path hooks/pre-commit)"

# Check if the pre-commit hook script exists and is executable.
# If it does, execute it passing the arguments from this script (if any) using the "exec" command.
test -x "$precommit" && exec "$precommit" ${1+"$@"}

# Be sure to exit without error if `exec` isn't called.
:
</file>

<file path="contracts/.git/hooks/pre-commit.sample">
#!/bin/sh
# A sample hook to prevent commits with merge-markers
#####################################################
# This example hook rejects changes that are about to be committed with merge markers,
# as that would be a clear indication of a failed merge. It is triggered by `git commit`
# and returning with non-zero exit status prevents the commit from being created.
#
# To enable this hook remove the `.sample` suffix from this file entirely.

# Check for merge markers in modified files
for file in $(git diff --cached --name-only); do
    if grep -q -E '^(<<<<<<<|=======|>>>>>>>|\|\|\|\|\|\|\|)$' "$file"; then
        echo "Error: File '$file' contains merge markers. Please remove them before committing."
        exit 1
    fi
done

# Exit with success if there are no errors
exit 0
</file>

<file path="contracts/.git/hooks/pre-merge-commit.sample">
#!/bin/sh
# A sample hook to check commits created by `git merge`
#######################################################
#
# This hook is invoked by `git merge` without further context right before creating a commit.
# It should be used to validate the current state that is supposed to be committed, or exit
# with a non-zero status to prevent the commit.
# All output will be visible to the user.
#
# To enable this hook remove the `.sample` suffix from this file entirely.

# Check if the pre-commit hook exists and is executable. If it is, it executes the pre-commit hook script.
test -x "$GIT_DIR/hooks/pre-commit" && exec "$GIT_DIR/hooks/pre-commit"

# Be sure to exit without error if `exec` isn't called.
:
</file>

<file path="contracts/.git/hooks/pre-push.sample">
#!/bin/sh
# Check for "DELME" in commit messages of about-to-be-pushed commits
####################################################################
# This hook script is triggered by `git push` right after a connection to the remote
# was established and its initial response was received, and right before generating
# and pushing a pack-file.
# The operation will be aborted when exiting with a non-zero status.
#
# The following arguments are provided:
#
# $1 - The symbolic name of the remote to push to, like "origin" or the URL like "https://github.com/GitoxideLabs/gitoxide" if there is no such name.
# $2 - The URL of the remote to push to, like "https://github.com/GitoxideLabs/gitoxide".
#
# The hook should then read from standard input in a line-by-line fashion and split the following space-separated fields:
#
# * local ref - the left side of a ref-spec, i.e. "local" of the "local:refs/heads/remote" ref-spec
# * local hash - the hash of the commit pointed to by `local ref`
# * remote ref - the right side of a ref-spec, i.e. "refs/heads/remote" of the "local:refs/heads/remote" ref-spec
# * remote hash - the hash of the commit pointed to by `remote ref`
#
# In this example, we abort the push if any of the about-to-be-pushed commits have "DELME" in their commit message.
#
# To enable this hook remove the `.sample` suffix from this file entirely.

remote="$1"
url="$2"

# Check each commit being pushed
while read _local_ref local_hash _remote_ref _remote_hash; do
  # Skip if the local hash is all zeroes (deletion)
  zero_sha=$(printf "%0${#local_hash}d" 0)
  if [ "$local_hash" = "$zero_sha" ]; then
    continue
  fi
  # Get the commit message
  commit_msg=$(git log --format=%s -n 1 "$local_hash")

  # Check if the commit message contains "DELME"
  if echo "$commit_msg" | grep -iq "DELME"; then
    echo "Error: Found commit with 'DELME' in message. Push aborted to $remote ($url) aborted." 1>&2
    exit 1
  fi
done

# If no commit with "DELME" found, allow the push
exit 0
</file>

<file path="contracts/.git/hooks/pre-rebase.sample">
#!/bin/sh
# A sample hook to validate the branches involved in a rebase operation
#######################################################################
#
# This hook is invoked right before `git rebase` starts its work and
# prevents anything else to happen by returning a non-zero exit code.
#
# The following arguments are provided:
#
# $1 - the branch that contains the commit from which $2 was forked.
# $2 - the branch being rebased or no second argument at all if the rebase applies to `HEAD`.
#
# This example hook aborts the rebase operation if the branch being rebased is not up to date
# with the latest changes from the upstream branch, or if there are any uncommitted changes.
#
# To enable this hook remove the `.sample` suffix from this file entirely.

upstream_branch=$1
if [ "$#" -eq 2 ]; then
  branch_being_rebased=$2
else
  branch_being_rebased=$(git symbolic-ref --quiet --short HEAD) || exit 0 # ignore rebases on detached heads
fi

# Check if the branch being rebased is behind the upstream branch
if git log --oneline ${upstream_branch}..${branch_being_rebased} > /dev/null; then
  echo "Warning: The branch being rebased (${branch_being_rebased}) is behind the upstream branch (${upstream_branch})." 1>&2
  echo "Please update your branch before rebasing." 1>&2
  exit 1
fi

# Check if there are any uncommitted changes
if ! git diff-index --quiet HEAD --; then
  echo "Warning: There are uncommitted changes in your branch ${branch_being_rebased}." 1>&2
  echo "Please commit or stash your changes before rebasing." 1>&2
  exit 2
fi

# All good, let the rebase proceed.
exit 0
</file>

<file path="contracts/.git/hooks/prepare-commit-msg.sample">
#!/bin/sh
# A hook called by `git commit` to adjust the commit message right before the user sees it
##########################################################################################
#
# This script is called by `git commit` after commit message was initialized and right before
# an editor is launched.
#
# It receives one to three arguments:
#
# $1 - the path to the file containing the commit message. It can be edited to change the message.
# $2 - the kind of source of the message contained in $1. Possible values are
#      "message" - a message was provided via `-m` or `-F`
#      "commit" - `-c`, `-C` or `--amend` was given
#      "squash" - the `.git/SQUASH_MSG` file exists
#      "merge" - this is a merge or the `.git/MERGE` file exists
#      "template" - `-t` was provided or `commit.template` was set
# $3 - If $2 is "commit" then this is the hash of the commit.
#      It can also take other values, best understood by studying the source code at
#      https://github.com/git/git/blob/aa9166bcc0ba654fc21f198a30647ec087f733ed/builtin/commit.c#L745
#
# The following example
#
# To enable this hook remove the `.sample` suffix from this file entirely.

COMMIT_MSG_FILE=$1

# Check if the commit message file is empty or already contains a message
if [ -s "$COMMIT_MSG_FILE" ]; then
  # If the commit message is already provided, exit without making any changes.
  # This can happen if the user provided a message via `-m` or a template.
  exit 0
fi

# Retrieve the branch name from the current HEAD commit
BRANCH_NAME=$(git symbolic-ref --short HEAD)

# Generate a default commit message based on the branch name
DEFAULT_MSG=""

case "$BRANCH_NAME" in
  "feature/*")
    DEFAULT_MSG="feat: "
    ;;
  "bugfix/*")
    DEFAULT_MSG="fix: "
    ;;
  *)
    DEFAULT_MSG="chore: "
    ;;
esac

# Set the commit message that will be presented to the user.
echo "$DEFAULT_MSG" > "$COMMIT_MSG_FILE"
</file>

<file path="contracts/.git/info/exclude">
# This file contains repository-wide exclude patterns that git will ignore.
# They are local and will not be shared when pushing or pulling.
# When using Rust the following would be typical exclude patterns.
# Remove the '# ' prefix to let them take effect.
# /target/
</file>

<file path="contracts/.git/logs/refs/heads/main">
0000000000000000000000000000000000000000 a144b2d0ab09e5717eac01d90474427b23cc274e chris <ngmi@posteo.es> 1748428408 +0200	clone: from https://github.com/EthGlobal-Paris/contracts.git
</file>

<file path="contracts/.git/logs/refs/remotes/origin/main">
0000000000000000000000000000000000000000 a144b2d0ab09e5717eac01d90474427b23cc274e chris <ngmi@posteo.es> 1748428408 +0200	clone: from https://github.com/EthGlobal-Paris/contracts.git
</file>

<file path="contracts/.git/logs/HEAD">
0000000000000000000000000000000000000000 a144b2d0ab09e5717eac01d90474427b23cc274e chris <ngmi@posteo.es> 1748428408 +0200	clone: from https://github.com/EthGlobal-Paris/contracts.git
</file>

<file path="contracts/.git/refs/heads/main">
a144b2d0ab09e5717eac01d90474427b23cc274e
</file>

<file path="contracts/.git/refs/remotes/origin/HEAD">
ref: refs/remotes/origin/main
</file>

<file path="contracts/.git/config">
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
	symlinks = true
	ignorecase = false
	precomposeunicode = false
[remote "origin"]
	url = https://github.com/EthGlobal-Paris/contracts.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "main"]
	remote = origin
	merge = refs/heads/main
	vscode-merge-base = origin/main
</file>

<file path="contracts/.git/description">
Unnamed repository; everything before the `;` is the name of the repository.
</file>

<file path="contracts/.git/FETCH_HEAD">
a144b2d0ab09e5717eac01d90474427b23cc274e		branch 'main' of https://github.com/EthGlobal-Paris/contracts
</file>

<file path="contracts/.git/HEAD">
ref: refs/heads/main
</file>

<file path="contracts/.git/packed-refs">
# pack-refs with: peeled fully-peeled sorted 
a144b2d0ab09e5717eac01d90474427b23cc274e refs/heads/main
a144b2d0ab09e5717eac01d90474427b23cc274e refs/remotes/origin/main
</file>

<file path="contracts/MinotaurPass.sol">
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.9;

import "@openzeppelin/contracts/token/ERC721/ERC721.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "./MinutaurUri.sol";

contract MinotaurPass is  MinutaurUri, Ownable {
    constructor() {
        tokenId = 1;
    }

    mapping(address => bool) authorized;
    mapping (address => uint256) ownerTokenId;
    uint256 tokenId;

    function setAuthorized(address addr, bool val) public onlyOwner{
        authorized[addr] = val;
    }

    function setValues(string memory _name_, string memory _description, string memory _imageUrl) public onlyOwner{
        _setValues(_name_, _description, _imageUrl);
    }

    function safeMint(address to) public {
        require(ownerTokenId[to] == 0, "Already Minted");

        ownerTokenId[to] = tokenId;

        _setTokenLastWing(tokenId, "00.00.00");

        tokenId++;

        _safeMint(to, tokenId -1);
    }

    function updateUri(address addr, string memory date) public {
        require(authorized[msg.sender], "caller not authorized");

        _setTokenLastWing(ownerTokenId[addr], date);

    }

    function checkOwnerTokenId(address addr) public view returns (uint256 id){
        return ownerTokenId[addr];
    }

    // The following functions are overrides required by Solidity.

    // Block token transfers
    function _beforeTokenTransfer(
        address from,
        address to,
        uint256 _tokenId, /* firstTokenId */
        uint256 batchSize
    ) internal virtual override{
    require(from == address(0), "Err: token transfer is BLOCKED");   
    super._beforeTokenTransfer(from, to, _tokenId, batchSize);  
    }

   
}
</file>

<file path="contracts/MinotaurToken.sol">
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.9;

import "@openzeppelin/contracts/token/ERC20/ERC20.sol";
import "@openzeppelin/contracts/security/Pausable.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "./MinotaurPass.sol";

contract MinotaurToken is ERC20, Pausable, Ownable {
    constructor(MinotaurPass _minotaurPass) ERC20("Minotaur", "MNT") {
        minotaurPass = _minotaurPass;
    }

    address[] players;

    uint lastRoundTime;

    uint256 incrementalTime;

    MinotaurPass immutable minotaurPass;

    function pause() public onlyOwner {
        _pause();
    }

    function unpause() public onlyOwner {
        _unpause();
    }

    //Add Voucher system in the future
    function mint(address to, uint256 amount, string memory date) public {
        require(block.timestamp + incrementalTime >= lastRoundTime);

        lastRoundTime = block.timestamp;
        minotaurPass.updateUri(to, date);
        delete players;
        _mint(to, amount);
        
    }

    function checkLastRoundTime() view public returns (bool) {
        require(block.timestamp + incrementalTime >= lastRoundTime);

        return true;
    }

    function startNewRound() public {
        require(block.timestamp + incrementalTime >= lastRoundTime);
        players.push(msg.sender);
    }

    function setIncreamental(uint256 time) public onlyOwner {
        incrementalTime = time;
    }

    function getPlayers() view public returns (address[] memory _players){
        return players;
    }

    function _beforeTokenTransfer(address from, address to, uint256 amount)
        internal
        whenNotPaused
        override
    {
        super._beforeTokenTransfer(from, to, amount);
    }
}
</file>

<file path="contracts/MinutaurUri.sol">
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.18;

import "@openzeppelin/contracts/token/ERC721/ERC721.sol";
import "@openzeppelin/contracts/utils/Base64.sol";

abstract contract MinutaurUri is ERC721 {

    mapping (uint256 => string) lastWin;

    string _name;
    string description;
    string imagenUrl;

    constructor()ERC721("MinotaurPass", "MNP"){
    }

    function _setValues(string memory _name_, string memory _description, string memory _imageUrl) internal {
        _name = _name_;
        description = _description;
        imagenUrl = _imageUrl;
    }

    function tokenURI(uint256 tokenId) public view virtual override returns (string memory) {
        _requireMinted(tokenId);

        string memory json = Base64.encode(
            bytes(
                string(
                    abi.encodePacked(
                    '{"name": "', _name,
                    '","description":"', description, 
                    '", "image": "', imagenUrl,
                    '", "tokenId": "', Strings.toString(tokenId),
                    '","attributes": [ { "trait_type": "last_win", "value": "',
                    lastWin[tokenId],               
                    '"} ]}'
                )

                )
            )
        );

        string memory output = string(
            abi.encodePacked("data:application/json;base64,", json)
        );

        return output;
    }

    function _setTokenLastWing(uint256 tokenId, string memory data) internal virtual {
        lastWin[tokenId] = data;
    }
 
}
</file>

<file path=".gitignore">
# Created by https://www.toptal.com/developers/gitignore/api/go
# Edit at https://www.toptal.com/developers/gitignore?templates=go

### Go ###
# If you prefer the allow list template instead of the deny list, see community template:
# https://github.com/github/gitignore/blob/main/community/Golang/Go.AllowList.gitignore
#
# Binaries for programs and plugins
*.exe
*.exe~
*.dll
*.so
*.dylib

# Test binary, built with `go test -c`
*.test

# Output of the go coverage tool, specifically when used with LiteIDE
*.out

# Dependency directories (remove the comment below to include it)
# vendor/

# Go workspace file
go.work

# End of https://www.toptal.com/developers/gitignore/api/go
</file>

<file path=".windurfrules">
1. use go 1.24 for typesafety and better performance
2. use go modules for dependency management
</file>

<file path="audit.prompt">
Audit the code for security vulnerabilities. Remember to check all of your reasoning. Avoid reporting false positives.
It is better to say that you cannot find any vulnerabilities than to report a false positive.
</file>

<file path="go.mod">
module sol.prompt

go 1.24.3
</file>

<file path="main.go">
package main

import (
	"context"
	"crypto/sha256"
	"encoding/hex"
	"fmt"
	"go/token"
	"io/fs"
	"os"
	"path/filepath"
	"regexp"
	"runtime"
	"slices"
	"strings"
	"sync"
	"time"
)

const (
	ProjectName    = "sol.prompt"
	MaxFileSize    = 50 * 1024 * 1024 // 50MB limit
	MaxConcurrency = 8
	TokenLimit     = 100000 // Rough token estimate for LLM context
)

// Enhanced type system for better categorization
type SecurityLevel uint8

const (
	SecurityCritical SecurityLevel = iota // Financial operations, access control
	SecurityHigh                          // State changes, user interactions
	SecurityMedium                        // View functions, events
	SecurityLow                           // Pure functions, constants
)

func (s SecurityLevel) String() string {
	return [...]string{"CRITICAL", "HIGH", "MEDIUM", "LOW"}[s]
}

type FunctionCategory uint8

const (
	CategoryUnknown   FunctionCategory = iota
	CategoryFinancial                  // Transfer, mint, burn, withdraw
	CategoryAccess                     // Owner, admin, role management
	CategoryState                      // State changing operations
	CategoryView                       // Read-only functions
	CategoryUtility                    // Helper functions
)

func (f FunctionCategory) String() string {
	return [...]string{"UNKNOWN", "FINANCIAL", "ACCESS", "STATE", "VIEW", "UTILITY"}[f]
}

// Enhanced visibility with more granular control
type Visibility uint8

const (
	VisibilityPrivate Visibility = iota
	VisibilityInternal
	VisibilityPublic
	VisibilityExternal
)

func (v Visibility) String() string {
	return [...]string{"private", "internal", "public", "external"}[v]
}

func (v Visibility) IsUserFacing() bool {
	return v == VisibilityPublic || v == VisibilityExternal
}

func (v Visibility) RiskScore() int {
	return [...]int{1, 2, 4, 5}[v] // Higher scores for more exposed functions
}

// Enhanced element types with better categorization
type ElementType uint8

const (
	ElementUnknown ElementType = iota
	ElementPragma
	ElementImport
	ElementContract
	ElementInterface
	ElementLibrary
	ElementFunction
	ElementModifier
	ElementEvent
	ElementError
	ElementStruct
	ElementEnum
	ElementStateVariable
	ElementMapping
	ElementConstructor
	ElementReceive
	ElementFallback
	ElementUsing
)

func (et ElementType) String() string {
	if et > ElementUsing { // Check bounds to prevent panic on out-of-range values
		return fmt.Sprintf("ElementType(%d)", et)
	}
	return [...]string{
		"UnknownElement",
		"Pragma",
		"Import",
		"Contract",
		"Interface",
		"Library",
		"Function",
		"Modifier",
		"Event",
		"ErrorDefinition", // Solidity custom error definition
		"Struct",
		"Enum",
		"StateVariable",
		"Mapping",
		"Constructor",
		"Receive",
		"Fallback",
		"UsingDirective",
	}[et]
}

// Comprehensive audit configuration
type AuditConfig struct {
	IncludePrivate      bool
	IncludeComments     bool
	IncludeTestImports  bool
	MaxTokens           int
	SecurityFocus       bool
	IncludeDependencies bool
	GenerateCallGraph   bool
	RiskAnalysis        bool
	OptimizeForModel    string // "gpt", "claude", "generic"
}

func NewOptimizedAuditConfig() AuditConfig {
	return AuditConfig{
		IncludePrivate:      false,
		IncludeComments:     true, // Keep security-relevant comments
		IncludeTestImports:  false,
		MaxTokens:           TokenLimit,
		SecurityFocus:       true,
		IncludeDependencies: true,
		GenerateCallGraph:   true,
		RiskAnalysis:        true,
		OptimizeForModel:    "generic",
	}
}

// Enhanced error types for better diagnostics
type ProcessingError struct {
	File        string
	Line        int
	Column      int
	Element     ElementType
	Severity    string
	Err         error
	Recoverable bool
}

func (e *ProcessingError) Error() string {
	return fmt.Sprintf("[%s] %s:%d:%d - %s: %v", e.Severity, e.File, e.Line, e.Column, e.Element, e.Err)
}

// Enhanced code element with security analysis
type CodeElement struct {
	Type          ElementType
	Content       string
	CleanContent  string
	Visibility    Visibility
	LineNumber    int
	IsComplete    bool
	SecurityLevel SecurityLevel
	Category      FunctionCategory
	Metadata      map[string]any
	Dependencies  []string
	CalledBy      []string
	Modifiers     []string
	RiskFactors   []string
	TokenEstimate int
}

// Function signature analysis
type FunctionSignature struct {
	Name       string
	Parameters []Parameter
	Returns    []Parameter
	Modifiers  []string
	Payable    bool
	StateMut   string // pure, view, payable, nonpayable
}

type Parameter struct {
	Type string
	Name string
}

// Enhanced contract analysis
type ContractFile struct {
	Path           string
	Name           string
	Hash           string
	Elements       []CodeElement
	Size           int64
	Functions      map[string]*FunctionSignature
	StateVars      []string
	Events         []string
	Errors         []string
	Inheritance    []string
	Dependencies   []string
	RiskScore      int
	TokenCount     int
	ProcessingTime time.Duration
}

// Comprehensive audit result with analytics
type AuditResult struct {
	Files           []ContractFile
	ProcessedAt     time.Time
	TotalLines      int
	FilteredLines   int
	Config          AuditConfig
	Summary         AuditSummary
	CallGraph       map[string][]string
	RiskAnalysis    RiskAnalysis
	Recommendations []string
	EstimatedTokens int
}

type AuditSummary struct {
	TotalContracts    int
	FilesAttempted    int64 // Number of files attempted for processing
	LinesProcessed    int64 // Total lines processed across all files
	RecoveredErrors   int64 // Number of errors recovered during processing
	PublicFunctions   int
	CriticalFunctions int
	StateVariables    int
	Events            int
	UniqueErrors      int
	ExternalCalls     int
	HighRiskPatterns  []string
}

type RiskAnalysis struct {
	CriticalFindings []string
	HighRiskFindings []string
	Patterns         map[string]int
	Recommendations  []string
}

// Resilient processor with recovery capabilities
type ResilientSolidityProcessor struct {
	patterns         map[ElementType]*regexp.Regexp
	securityPatterns map[string]SecurityLevel
	categoryPatterns map[string]FunctionCategory
	tokenizer        *token.FileSet
	mu               sync.RWMutex
	stats            ProcessingStats
}

type ProcessingStats struct {
	FilesProcessed  int64
	LinesProcessed  int64
	ErrorsRecovered int64
	TokensEstimated int64
}

func NewResilientProcessor() *ResilientSolidityProcessor {
	processor := &ResilientSolidityProcessor{
		patterns: map[ElementType]*regexp.Regexp{
			ElementPragma:        regexp.MustCompile(`^\s*pragma\s+([^;]+);?`),
			ElementImport:        regexp.MustCompile(`^\s*import\s+(.+);`),
			ElementContract:      regexp.MustCompile(`^\s*(abstract\s+)?(contract|interface|library)\s+(\w+)(\s+is\s+([^{]+))?`),
			ElementFunction:      regexp.MustCompile(`^\s*function\s+(\w+)\s*\([^)]*\)([^{;]*)[{;]`),
			ElementConstructor:   regexp.MustCompile(`^\s*constructor\s*\([^)]*\)([^{]*)`),
			ElementModifier:      regexp.MustCompile(`^\s*modifier\s+(\w+)\s*(\([^)]*\))?([^{]*)`),
			ElementEvent:         regexp.MustCompile(`^\s*event\s+(\w+)\s*\([^)]*\);?`),
			ElementError:         regexp.MustCompile(`^\s*error\s+(\w+)\s*(\([^)]*\))?;?`),
			ElementStruct:        regexp.MustCompile(`^\s*struct\s+(\w+)\s*{`),
			ElementEnum:          regexp.MustCompile(`^\s*enum\s+(\w+)\s*{`),
			ElementStateVariable: regexp.MustCompile(`^\s*(mapping\s*\([^)]+\)|uint\d*|int\d*|bool|address|string|bytes\d*)\s+(\w+)`),
			ElementMapping:       regexp.MustCompile(`^\s*mapping\s*\([^)]+\)\s*(\w+)`),
			ElementReceive:       regexp.MustCompile(`^\s*receive\s*\(\s*\)\s*external\s+payable`),
			ElementFallback:      regexp.MustCompile(`^\s*fallback\s*\([^)]*\)\s*external`),
			ElementUsing:         regexp.MustCompile(`^\s*using\s+(\w+)\s+for\s+([^;]+);`),
		},
		securityPatterns: map[string]SecurityLevel{
			"transfer":     SecurityCritical,
			"withdraw":     SecurityCritical,
			"mint":         SecurityCritical,
			"burn":         SecurityCritical,
			"approve":      SecurityCritical,
			"transferFrom": SecurityCritical,
			"selfdestruct": SecurityCritical,
			"delegatecall": SecurityCritical,
			"call":         SecurityHigh,
			"send":         SecurityHigh,
			"onlyOwner":    SecurityHigh,
			"onlyAdmin":    SecurityHigh,
			"require":      SecurityMedium,
			"assert":       SecurityMedium,
			"view":         SecurityLow,
			"pure":         SecurityLow,
		},
		categoryPatterns: map[string]FunctionCategory{
			"transfer|withdraw|deposit|mint|burn|approve": CategoryFinancial,
			"owner|admin|role|access|auth":                CategoryAccess,
			"set|update|change|modify":                    CategoryState,
			"get|view|read|check":                         CategoryView,
			"_|internal|helper":                           CategoryUtility,
		},
		tokenizer: token.NewFileSet(),
	}
	return processor
}

var spaceRegex = regexp.MustCompile(`\s+`)

func (rsp *ResilientSolidityProcessor) ProcessLine(line string, lineNum int, fileName string) (CodeElement, *ProcessingError) {
	defer func() {
		if r := recover(); r != nil {
			// Log panic but continue processing
			fmt.Printf("Recovered from panic in %s:%d: %v\n", fileName, lineNum, r)
		}
	}()

	rsp.mu.Lock()
	rsp.stats.LinesProcessed++
	rsp.mu.Unlock()

	trimmed := strings.TrimSpace(line)
	if trimmed == "" || strings.HasPrefix(trimmed, "//") {
		return CodeElement{Type: ElementUnknown}, nil
	}

	element := CodeElement{
		Content:       line,
		CleanContent:  rsp.cleanLine(trimmed),
		LineNumber:    lineNum,
		IsComplete:    true,
		Metadata:      make(map[string]any),
		TokenEstimate: rsp.estimateTokens(line),
	}

	// Pattern matching with error recovery
	matched := false
	for elemType, pattern := range rsp.patterns {
		if matches := pattern.FindStringSubmatch(trimmed); matches != nil {
			element.Type = elemType
			element = rsp.enrichElement(element, matches, trimmed)
			matched = true
			break
		}
	}

	if !matched {
		// Try to infer type from context
		element.Type = rsp.inferElementType(trimmed)
	}

	// Security and category analysis
	element.SecurityLevel = rsp.analyzeSecurityLevel(trimmed)
	element.Category = rsp.analyzeCategory(trimmed)
	element.RiskFactors = rsp.identifyRiskFactors(trimmed)

	return element, nil
}

func (rsp *ResilientSolidityProcessor) cleanLine(line string) string {
	cleanedLine := line // Assume line is kept as is, unless a non-special comment is found

	if idx := strings.Index(line, "//"); idx != -1 {
		// Found a "//"
		commentContent := line[idx+2:] // Text after "//"

		// Trim leading whitespace from the comment content itself
		trimmedCommentText := strings.TrimLeft(commentContent, " \t")

		// Check if the trimmed comment content starts with '@' or '/'
		isSpecialComment := false
		if len(trimmedCommentText) > 0 {
			if trimmedCommentText[0] == '@' || trimmedCommentText[0] == '/' {
				isSpecialComment = true
			}
		}

		if !isSpecialComment {
			// It's a normal comment, so remove it.
			// The cleaned line is the part before the comment, with trailing spaces trimmed from the code part.
			cleanedLine = strings.TrimRight(line[:idx], " \t")
		}
		// If it's a special comment, cleanedLine remains the original 'line', so the comment is preserved.
	}

	// Normalize whitespace on the potentially modified line
	// Trim leading/trailing whitespace from the entire line first, then replace multiple spaces with a single space.
	finalCleaned := spaceRegex.ReplaceAllString(strings.TrimSpace(cleanedLine), " ")

	return finalCleaned
}

func (rsp *ResilientSolidityProcessor) estimateTokens(text string) int {
	// Rough GPT tokenization estimate: ~4 chars per token
	return len(text) / 4
}

func (rsp *ResilientSolidityProcessor) enrichElement(element CodeElement, matches []string, line string) CodeElement {
	switch element.Type {
	case ElementContract, ElementInterface, ElementLibrary:
		if len(matches) > 3 {
			element.Metadata["name"] = matches[3]
			if len(matches) > 5 && matches[5] != "" {
				element.Metadata["inheritance"] = strings.Split(matches[5], ",")
			}
		}
	case ElementFunction:
		element.Visibility = extractVisibility(line)
		element.Metadata["name"] = matches[1]
		element.Metadata["signature"] = rsp.extractFunctionSignature(line)
		element.Modifiers = rsp.extractModifiers(line)
	case ElementStateVariable:
		element.Visibility = extractVisibility(line)
		if len(matches) > 2 {
			element.Metadata["name"] = matches[2]
			element.Metadata["type"] = matches[1]
		}
	}
	return element
}

func (rsp *ResilientSolidityProcessor) inferElementType(line string) ElementType {
	line = strings.ToLower(line)

	if strings.Contains(line, "function") {
		return ElementFunction
	}
	if strings.Contains(line, "event") {
		return ElementEvent
	}
	if strings.Contains(line, "modifier") {
		return ElementModifier
	}

	return ElementUnknown
}

func (rsp *ResilientSolidityProcessor) analyzeSecurityLevel(line string) SecurityLevel {
	line = strings.ToLower(line)

	for pattern, level := range rsp.securityPatterns {
		if strings.Contains(line, pattern) {
			return level
		}
	}

	// Additional heuristics
	if strings.Contains(line, "payable") || strings.Contains(line, "ether") {
		return SecurityCritical
	}
	if strings.Contains(line, "external") || strings.Contains(line, "public") {
		return SecurityHigh
	}

	return SecurityLow
}

func (rsp *ResilientSolidityProcessor) analyzeCategory(line string) FunctionCategory {
	line = strings.ToLower(line)

	for pattern, category := range rsp.categoryPatterns {
		if matched, _ := regexp.MatchString(pattern, line); matched {
			return category
		}
	}

	return CategoryUnknown
}

func (rsp *ResilientSolidityProcessor) identifyRiskFactors(line string) []string {
	var risks []string
	line = strings.ToLower(line)

	riskPatterns := map[string]string{
		"delegatecall":    "Dangerous delegatecall usage",
		"tx.origin":       "tx.origin authentication vulnerability",
		"block.timestamp": "Block timestamp manipulation risk",
		"block.number":    "Block number dependency",
		"selfdestruct":    "Contract destruction capability",
		"assembly":        "Inline assembly usage",
		"unchecked":       "Unchecked arithmetic operations",
		"call.value":      "Direct call with value transfer",
	}

	for pattern, risk := range riskPatterns {
		if strings.Contains(line, pattern) {
			risks = append(risks, risk)
		}
	}

	return risks
}

func (rsp *ResilientSolidityProcessor) extractFunctionSignature(line string) string {
	// Extract complete function signature
	funcRegex := regexp.MustCompile(`function\s+(\w+)\s*\([^)]*\)([^{;]*)`)
	if matches := funcRegex.FindStringSubmatch(line); matches != nil {
		return strings.TrimSpace(matches[0])
	}
	return ""
}

func (rsp *ResilientSolidityProcessor) extractModifiers(line string) []string {
	var modifiers []string

	// Common modifiers
	modifierPatterns := []string{
		`onlyOwner`, `onlyAdmin`, `whenNotPaused`, `nonReentrant`,
		`validAddress`, `notZero`, `initialized`,
	}

	for _, pattern := range modifierPatterns {
		if matched, _ := regexp.MatchString(pattern, line); matched {
			modifiers = append(modifiers, pattern)
		}
	}

	return modifiers
}

func extractVisibility(line string) Visibility {
	switch {
	case strings.Contains(line, "public"):
		return VisibilityPublic
	case strings.Contains(line, "external"):
		return VisibilityExternal
	case strings.Contains(line, "internal"):
		return VisibilityInternal
	case strings.Contains(line, "private"):
		return VisibilityPrivate
	default:
		return VisibilityInternal
	}
}

// Concurrent file processing with worker pools
func processFilesConcurrently(ctx context.Context, filePaths []string, processor *ResilientSolidityProcessor, config AuditConfig) ([]ContractFile, error) {
	filesChan := make(chan string, len(filePaths))
	resultsChan := make(chan ContractFile, len(filePaths))
	errorsChan := make(chan error, len(filePaths))

	// Limit concurrency
	numWorkers := min(MaxConcurrency, runtime.NumCPU())
	var wg sync.WaitGroup

	// Start workers
	for i := 0; i < numWorkers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for filePath := range filesChan {
				select {
				case <-ctx.Done():
					return
				default:
					if file, err := processFile(ctx, filePath, processor, config); err != nil {
						errorsChan <- err
					} else {
						resultsChan <- file
					}
				}
			}
		}()
	}

	// Send files to workers
	go func() {
		for _, path := range filePaths {
			filesChan <- path
		}
		close(filesChan)
	}()

	// Wait for completion
	go func() {
		wg.Wait()
		close(resultsChan)
		close(errorsChan)
	}()

	// Collect results
	var files []ContractFile
	var errors []error

	for {
		select {
		case file, ok := <-resultsChan:
			if !ok {
				resultsChan = nil
			} else {
				files = append(files, file)
			}
		case err, ok := <-errorsChan:
			if !ok {
				errorsChan = nil
			} else {
				errors = append(errors, err)
			}
		}

		if resultsChan == nil && errorsChan == nil {
			break
		}
	}

	// Report errors but continue
	for _, err := range errors {
		fmt.Printf("Processing error: %v\n", err)
	}

	return files, nil
}

func processFile(ctx context.Context, filePath string, processor *ResilientSolidityProcessor, config AuditConfig) (ContractFile, error) {
	startTime := time.Now()

	// File size validation
	fileInfo, err := os.Stat(filePath)
	if err != nil {
		return ContractFile{}, fmt.Errorf("failed to stat file %s: %w", filePath, err)
	}

	if fileInfo.Size() > MaxFileSize {
		return ContractFile{}, fmt.Errorf("file %s too large: %d bytes", filePath, fileInfo.Size())
	}

	content, err := os.ReadFile(filePath)
	if err != nil {
		return ContractFile{}, fmt.Errorf("failed to read file %s: %w", filePath, err)
	}

	// Generate file hash for integrity
	hash := sha256.Sum256(content)

	lines := strings.Split(string(content), "\n")
	var elements []CodeElement
	var errorCount int

	fileName := filepath.Base(filePath)

	for i, line := range lines {
		select {
		case <-ctx.Done():
			return ContractFile{}, ctx.Err()
		default:
		}

		element, procErr := processor.ProcessLine(line, i+1, fileName)

		if procErr != nil {
			errorCount++
			if !procErr.Recoverable {
				fmt.Printf("Unrecoverable error in %s: %v\n", filePath, procErr)
				continue
			}
		}

		if shouldIncludeElement(element, config) {
			elements = append(elements, element)
		}
	}

	file := ContractFile{
		Path:           filePath,
		Name:           fileName,
		Hash:           hex.EncodeToString(hash[:]),
		Elements:       elements,
		Size:           fileInfo.Size(),
		Functions:      make(map[string]*FunctionSignature),
		ProcessingTime: time.Since(startTime),
	}

	// Post-processing analysis
	file = analyzeContract(file)

	processor.mu.Lock()
	processor.stats.FilesProcessed++
	processor.stats.ErrorsRecovered += int64(errorCount)
	processor.mu.Unlock()

	return file, nil
}

func shouldIncludeElement(element CodeElement, config AuditConfig) bool {
	if element.Type == ElementUnknown {
		return false
	}

	// Always include high-security elements
	if element.SecurityLevel == SecurityCritical {
		return true
	}

	// Include based on visibility and configuration
	if element.Visibility.IsUserFacing() {
		return true
	}

	if config.IncludePrivate && element.Visibility == VisibilityPrivate {
		return true
	}

	// Include important structural elements
	importantTypes := []ElementType{
		ElementPragma, ElementContract, ElementInterface, ElementLibrary,
		ElementEvent, ElementError, ElementModifier, ElementConstructor,
		ElementStateVariable, ElementMapping,
	}

	return slices.Contains(importantTypes, element.Type)
}

func analyzeContract(file ContractFile) ContractFile {
	// Extract function signatures and analyze relationships
	for _, element := range file.Elements {
		if element.Type == ElementFunction {
			if name, ok := element.Metadata["name"].(string); ok {
				file.Functions[name] = &FunctionSignature{
					Name:      name,
					Modifiers: element.Modifiers,
				}
			}
		}
	}

	// Calculate risk score
	file.RiskScore = calculateRiskScore(file)

	// Estimate token count
	tokenCount := 0
	for _, element := range file.Elements {
		tokenCount += element.TokenEstimate
	}
	file.TokenCount = tokenCount

	return file
}

func calculateRiskScore(file ContractFile) int {
	score := 0

	for _, element := range file.Elements {
		score += int(element.SecurityLevel) * element.Visibility.RiskScore()
		score += len(element.RiskFactors) * 5
	}

	return score
}

// Optimized LLM output generation - now generates XML
func generateOptimizedOutput(result AuditResult) string {
	var builder strings.Builder
	// Estimate size: ~50 chars per contract for tags + total estimated tokens for content
	// Add a buffer for CDATA tags and newlines.
	builder.Grow(len(result.Files)*100 + result.EstimatedTokens*2) // Adjusted pre-allocation for XML

	builder.WriteString("<contracts>\n")

	for _, file := range result.Files {
		builder.WriteString(fmt.Sprintf("  <contract name=\"%s\">\n", escapeXML(file.Name)))
		builder.WriteString("    <![CDATA[\n")

		// Concatenate content of all elements for this file
		// We'll use the original order of elements as they appear in the file.
		// The `file.Elements` should already be in the correct order from parsing.
		var contractContentBuilder strings.Builder
		for _, element := range file.Elements {
			// We can include the annotations if they are helpful for the LLM
			// For now, let's stick to the raw element.Content as per previous findings.
			// If annotations are needed, the logic from writeElements can be adapted here.
			contractContentBuilder.WriteString(element.Content)
			contractContentBuilder.WriteString("\n") // Add a newline between elements for readability
		}
		builder.WriteString(strings.TrimSpace(contractContentBuilder.String()))
		builder.WriteString("\n    ]]>\n")
		builder.WriteString("  </contract>\n")
	}

	builder.WriteString("</contracts>")

	return builder.String()
}

// escapeXML is a helper function to escape characters that have special meaning in XML.
// Added to support filenames or other attributes that might contain such characters.
func escapeXML(s string) string {
	var esc strings.Builder
	for _, r := range s {
		switch r {
		case '&':
			esc.WriteString("&amp;")
		case '<':
			esc.WriteString("&lt;")
		case '>':
			esc.WriteString("&gt;")
		case '\'':
			esc.WriteString("&apos;")
		case '"':
			esc.WriteString("&quot;")
		default:
			esc.WriteRune(r)
		}
	}
	return esc.String()
}

func main() {
	if len(os.Args) < 2 {
		fmt.Printf("Usage: %s <solidity_folder_path> [--include-private] [--security-focus]\n", ProjectName)
		os.Exit(1)
	}

	folderPath := os.Args[1]
	config := NewOptimizedAuditConfig()

	// Parse command line arguments
	for _, arg := range os.Args[2:] {
		switch arg {
		case "--include-private":
			config.IncludePrivate = true
		case "--security-focus":
			config.SecurityFocus = true
		case "--include-test":
			config.IncludeTestImports = true
		case "--optimize-gpt":
			config.OptimizeForModel = "gpt"
		case "--optimize-claude":
			config.OptimizeForModel = "claude"
		}
	}

	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Minute)
	defer cancel()

	fmt.Printf("🔍 %s - Smart Contract Security Audit Preparation\n", ProjectName)
	fmt.Printf("📁 Analyzing: %s\n", folderPath)

	// Discover Solidity files
	var filePaths []string
	err := filepath.WalkDir(folderPath, func(path string, d fs.DirEntry, err error) error {
		if err != nil {
			return err
		}
		if !d.IsDir() && strings.HasSuffix(strings.ToLower(path), ".sol") {
			filePaths = append(filePaths, path)
		}
		return nil
	})

	if err != nil {
		fmt.Printf("❌ Error walking directory: %v\n", err)
		os.Exit(1)
	}

	if len(filePaths) == 0 {
		fmt.Println("❌ No Solidity files found")
		os.Exit(1)
	}

	fmt.Printf("📄 Found %d Solidity files\n", len(filePaths))

	// Process files concurrently
	processor := NewResilientProcessor()
	files, err := processFilesConcurrently(ctx, filePaths, processor, config)
	if err != nil {
		fmt.Printf("❌ Processing error: %v\n", err)
		os.Exit(1)
	}

	// Generate comprehensive audit result
	auditResult := generateAuditResult(files, config, processor.stats)

	// Generate optimized output
	output := generateOptimizedOutput(auditResult)

	// Write to sol.prompt
	if err := os.WriteFile(ProjectName, []byte(output), 0644); err != nil {
		fmt.Printf("❌ Error writing %s: %v\n", ProjectName, err)
		os.Exit(1)
	}

	// Success metrics
	fmt.Printf("✅ Successfully generated %s\n", ProjectName)
	fmt.Printf("📊 Statistics:\n")
	fmt.Printf("   - Files processed: %d\n", len(files))
	fmt.Printf("   - Critical functions: %d\n", auditResult.Summary.CriticalFunctions)
	fmt.Printf("   - Estimated tokens: %d\n", auditResult.EstimatedTokens)
	fmt.Printf("   - Risk patterns found: %d\n", len(auditResult.Summary.HighRiskPatterns))

	if auditResult.EstimatedTokens > TokenLimit {
		fmt.Printf("⚠️  Warning: Output may exceed LLM context limits (%d tokens)\n", TokenLimit)
	}
}

func generateAuditResult(files []ContractFile, config AuditConfig, stats ProcessingStats) AuditResult {
	summary := AuditSummary{
		TotalContracts: len(files),
		FilesAttempted: stats.FilesProcessed,
		LinesProcessed: stats.LinesProcessed,
		RecoveredErrors: stats.ErrorsRecovered,
	}

	var totalTokens int
	var criticalFindings []string

	for _, file := range files {
		totalTokens += file.TokenCount

		for _, element := range file.Elements {
			if element.Visibility.IsUserFacing() {
				if element.Type == ElementFunction {
					summary.PublicFunctions++
				}
			}

			if element.SecurityLevel == SecurityCritical {
				summary.CriticalFunctions++
			}

			if len(element.RiskFactors) > 0 {
				criticalFindings = append(criticalFindings, element.RiskFactors...)
			}
		}
	}

	// Deduplicate findings
	summary.HighRiskPatterns = deduplicateStrings(criticalFindings)

	return AuditResult{
		Files:           files,
		ProcessedAt:     time.Now(),
		TotalLines:      int(stats.LinesProcessed),
		FilteredLines:   0,                       // TODO: Populate this if applicable
		Config:          config,
		Summary:         summary,
		CallGraph:       nil, // TODO: Populate this if applicable
		RiskAnalysis: RiskAnalysis{
			CriticalFindings: summary.HighRiskPatterns,
		},
		Recommendations: nil, // TODO: Populate this if applicable
		EstimatedTokens: totalTokens,
	}
}

func deduplicateStrings(input []string) []string {
	seen := make(map[string]bool)
	var result []string

	for _, item := range input {
		if !seen[item] {
			seen[item] = true
			result = append(result, item)
		}
	}

	return result
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}
</file>

<file path="sol.prompt">
<contracts>
  <contract name="MinotaurPass.sol">
    <![CDATA[
pragma solidity ^0.8.9;
contract MinotaurPass is  MinutaurUri, Ownable {
    constructor() {
    mapping(address => bool) authorized;
    mapping (address => uint256) ownerTokenId;
    uint256 tokenId;
    function setAuthorized(address addr, bool val) public onlyOwner{
    function setValues(string memory _name_, string memory _description, string memory _imageUrl) public onlyOwner{
    function safeMint(address to) public {
    function updateUri(address addr, string memory date) public {
    function checkOwnerTokenId(address addr) public view returns (uint256 id){
    function _beforeTokenTransfer(
        address from,
        address to,
        uint256 _tokenId, /* firstTokenId */
        uint256 batchSize
    ]]>
  </contract>
  <contract name="MinutaurUri.sol">
    <![CDATA[
pragma solidity ^0.8.18;
abstract contract MinutaurUri is ERC721 {
    mapping (uint256 => string) lastWin;
    string _name;
    string description;
    string imagenUrl;
    constructor()ERC721("MinotaurPass", "MNP"){
    function tokenURI(uint256 tokenId) public view virtual override returns (string memory) {
        string memory json = Base64.encode(
        string memory output = string(
    ]]>
  </contract>
  <contract name="MinotaurToken.sol">
    <![CDATA[
pragma solidity ^0.8.9;
contract MinotaurToken is ERC20, Pausable, Ownable {
    constructor(MinotaurPass _minotaurPass) ERC20("Minotaur", "MNT") {
    uint lastRoundTime;
    uint256 incrementalTime;
    function pause() public onlyOwner {
    function unpause() public onlyOwner {
    function mint(address to, uint256 amount, string memory date) public {
    function checkLastRoundTime() view public returns (bool) {
    function startNewRound() public {
    function setIncreamental(uint256 time) public onlyOwner {
    function getPlayers() view public returns (address[] memory _players){
    function _beforeTokenTransfer(address from, address to, uint256 amount)
    ]]>
  </contract>
</contracts>
</file>

<file path="README.md">
# sol.prompt

A high-performance, type-safe Go tool that prepares Solidity smart contracts for AI-powered security auditing. Extracts, analyzes, and optimizes contract code to create LLM-ready audit prompts with security-focused organization.

## 🔍 Features

### Core Functionality
- **Smart Contract Analysis**: Automatically discovers and processes all `.sol` files in a directory
- **Security-First Organization**: Prioritizes critical functions and high-risk code patterns (internal analysis)
- **LLM Optimization**: Generates XML-structured output containing cleaned contract code, optimized for AI security analysis
- **Risk Assessment**: Identifies and categorizes security risks in smart contracts
- **Concurrent Processing**: High-performance parallel file processing with worker pools

### Security Analysis
- **Vulnerability Detection**: Identifies common patterns like reentrancy, tx.origin usage, delegatecall risks
- **Access Control Analysis**: Extracts and highlights permission-based functions
- **Function Categorization**: Classifies functions by risk level (Critical/High/Medium/Low)
- **Modifier Extraction**: Identifies security modifiers and access controls
- **Token Estimation**: Estimates output size for LLM context limits

### Code Intelligence
- **Type-Safe Processing**: Robust error handling with recovery mechanisms
- **Smart Filtering**: Removes test code, comments, and irrelevant imports
- **Dependency Tracking**: Maps contract relationships and inheritance
- **Risk Scoring**: Quantitative risk assessment for each contract

## 🚀 Installation

### Prerequisites
- Go 1.23 or later
- Access to Solidity contract files

### Install from Source
```bash
git clone <repository-url>
cd sol.prompt
go build -o sol.prompt .
```

### Direct Run
```bash
go run . <path-to-contracts>
```

## 📖 Usage

### Basic Usage
```bash
# Analyze contracts in current directory
./sol.prompt ./contracts

# Analyze with security focus
./sol.prompt ./contracts --security-focus

# Include private functions
./sol.prompt ./contracts --include-private
```

### Command Line Options

| Option | Description | Default |
|--------|-------------|---------|
| `--security-focus` | Enhanced security analysis and risk detection | `false` |
| `--include-private` | Include private/internal functions in output | `false` |
| `--include-test` | Include test-related imports and functions | `false` |
| `--optimize-gpt` | Optimize output format for GPT models | `generic` |
| `--optimize-claude` | Optimize output format for Claude models | `generic` |

### Examples

```bash
# Full security audit preparation
./sol.prompt ./src/contracts --security-focus --include-private

# Quick audit for public functions only
./sol.prompt ./contracts 

# Optimize for specific LLM
./sol.prompt ./contracts --optimize-claude --security-focus
```

## 📄 Output Format

The tool generates a `sol.prompt` file in XML format. This file contains the cleaned content of each processed Solidity contract, structured for easy parsing and ingestion by other tools or LLMs.

The basic XML structure is as follows:

```xml
<contracts>
  <contract name="ContractA.sol">
    <![CDATA[
// Cleaned content of ContractA.sol
// (pragma directives, imports, contract code, etc.)
// ...
// All elements of the contract are concatenated here.
    ]]>
  </contract>
  <contract name="ContractB.sol">
    <![CDATA[
// Cleaned content of ContractB.sol
// ...
    ]]>
  </contract>
  <!-- Additional contracts follow the same pattern -->
</contracts>
```

Key aspects of the XML output:
- Each Solidity file is represented by a `<contract>` element.
- The `name` attribute of the `<contract>` tag holds the original filename.
- The entire cleaned content of the contract is placed within a `<![CDATA[...]]>` section. This ensures that all Solidity syntax, including special characters, is preserved literally and doesn't interfere with XML parsing.
- The "cleaned content" consists of the concatenated `Content` of all code elements extracted from the Solidity file, in their original order. This typically includes pragma directives, import statements, contract definitions, functions, state variables, etc., after non-essential comments (excluding NatSpec and special annotations) have been stripped.

## 🔒 Security Focus Areas

The tool automatically identifies and highlights:

### Critical Patterns
- Financial operations (transfer, withdraw, mint, burn)
- Access control functions (onlyOwner, onlyAdmin)
- Dangerous operations (delegatecall, selfdestruct)
- External calls and value transfers

### Risk Factors
- **Reentrancy vulnerabilities**
- **tx.origin authentication**
- **Block timestamp dependencies**
- **Unchecked arithmetic operations**
- **Assembly usage**
- **Direct call.value transfers**

### Function Categories
- **Financial**: Money-related operations
- **Access**: Permission and role management  
- **State**: State-changing functions
- **View**: Read-only functions
- **Utility**: Helper and internal functions

## 🎯 LLM Integration

### Optimized for AI Analysis
- **XML structure** for easy parsing by LLMs and other tools
- **Context-aware token management** to stay within limits (internal estimation)

### Token Management
- Automatic token estimation for each contract
- Warning when approaching LLM context limits (100,000 tokens)
- Smart filtering to include only security-relevant code

### AI Model Optimization
- **Generic**: Balanced output for any LLM
- **GPT**: Optimized for OpenAI GPT models
- **Claude**: Optimized for Anthropic Claude models

## 📊 Performance

### Specifications
- **Concurrent Processing**: Up to 8 parallel workers
- **File Size Limit**: 50MB per contract file
- **Memory Efficient**: Streaming processing for large codebases
- **Error Recovery**: Continues processing despite individual file errors

### Benchmarks
- Processes ~1,000 lines of Solidity per second
- Handles entire DeFi protocol codebases (100+ contracts)
- Reduces code size by 60-80% while preserving security relevance

## 🛠️ Development

### Project Structure
```
sol.prompt/
├── main.go                 # Core application logic
├── go.mod                  # Go module definition
├── README.md              # This file
└── examples/              # Example usage and outputs
    ├── sample-contracts/   # Test Solidity files
    └── sample-output.xml   # Example sol.prompt output
```

### Building
```bash
# Build for current platform
go build -o sol.prompt .

# Cross-compile for Linux
GOOS=linux GOARCH=amd64 go build -o sol.prompt-linux .

# Cross-compile for Windows
GOOS=windows GOARCH=amd64 go build -o sol.prompt.exe .
```

### Testing
```bash
# Run with sample contracts
go run . ./examples/sample-contracts --security-focus

# Test concurrent processing
go run . ./large-codebase --include-private
```

## 🤝 Contributing

### Development Setup
1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Make your changes with proper error handling
4. Add tests for new functionality
5. Submit a pull request

### Code Standards
- Follow Go conventions and formatting (`go fmt`)
- Include comprehensive error handling
- Add security pattern recognition for new vulnerability types
- Maintain type safety and performance optimization

### Feature Requests
We welcome contributions for:
- New security pattern detection
- Additional LLM optimizations
- Performance improvements
- Enhanced risk scoring algorithms

## 📋 Roadmap

- [ ] **v2.0**: GraphQL API for integration with audit platforms
- [ ] **v2.1**: Real-time contract monitoring and diff analysis  
- [ ] **v2.2**: Integration with popular development frameworks
- [ ] **v2.3**: Machine learning-based risk scoring
- [ ] **v2.4**: Multi-language support (Vyper, Move, etc.)

## 📄 License

This project is licensed under the MIT License - see the LICENSE file for details.

## 🙏 Acknowledgments

- Solidity compiler team for language specifications
- OpenZeppelin for security pattern references
- Trail of Bits for audit methodology inspiration
- Go team for excellent concurrency primitives

## 📞 Support

For questions, issues, or feature requests:
- Create an issue on GitHub
- Join our Discord community
- Follow us on Twitter for updates

---

**sol.prompt** - Making smart contract security auditing more accessible and efficient through AI-powered analysis.
</file>

</files>
